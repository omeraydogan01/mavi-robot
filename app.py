import os
import streamlit as st
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.chains.question_answering import load_qa_chain

def main():
    st.set_page_config(page_title="Mavi Soru Robotu", page_icon="logo.png")
    
    # CSS - Browse files butonunu ve soru alanÄ±nÄ± Ã¶zelleÅŸtir
    st.markdown(
        """
        <style>
        /* PDF yÃ¼kle butonu */
        button[data-testid="stFileUploaderBrowseButton"] {
            background-color: #2e86de;
            color: white;
            border-radius: 8px;
        }
        button[data-testid="stFileUploaderBrowseButton"]::after {
            content: " Dosya SeÃ§";
        }
        button[data-testid="stFileUploaderBrowseButton"] > div {
            display: none;
        }

        /* Soru alanÄ± mavi Ã§erÃ§eve */
        div[data-testid="stTextArea"] textarea {
            border: 3px solid #1E90FF;
            border-radius: 8px;
            padding: 10px;
            font-size: 16px;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    # Header ve logo yan yana
    col1, col2 = st.columns([1, 6])
    with col1:
        st.image("logo.png", width=120)
    with col2:
        st.header("DokÃ¼mana Soru Sor")

    # API key kontrolÃ¼
    api_key = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY")
    if not api_key:
        st.error("âš ï¸ API key bulunamadÄ±. LÃ¼tfen secrets veya environment deÄŸiÅŸkeni ekleyin.")
        st.stop()

    uploaded_file = st.file_uploader("ğŸ“‚ DokÃ¼man yÃ¼kleyin", type="pdf")
    if uploaded_file is not None:
        pdf_reader = PdfReader(uploaded_file)
        text = "".join([page.extract_text() or "" for page in pdf_reader.pages])
        
        st.info(f"ğŸ“„ YÃ¼klenen dokÃ¼man toplam **{len(pdf_reader.pages)}** sayfa iÃ§eriyor.")

        # Metin parÃ§alama
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=2000,
            chunk_overlap=200
        )
        chunks = text_splitter.split_text(text)

        # Embedding modeli
        embeddings = OpenAIEmbeddings(
            model="text-embedding-3-large",
            openai_api_key=api_key
        )

        # FAISS vektÃ¶r veritabanÄ± (cache'li)
        @st.cache_resource
        def create_vectorstore(chunks, embeddings):
            return FAISS.from_texts(chunks, embeddings)
        
        vectorstore = create_vectorstore(chunks, embeddings)

        # KullanÄ±cÄ± sorusu (mavi Ã§erÃ§eveli alan)
        user_question = st.text_area("Sorunuzu yazÄ±n ğŸ‘‡", height=130)

        if user_question:
            # Daha fazla chunk â†’ daha saÄŸlam cevap
            docs = vectorstore.similarity_search(user_question, k=6)

            # Daha hÄ±zlÄ± ve ucuz model
            llm = ChatOpenAI(
                model="gpt-4o-mini",
                temperature=0,
                api_key=api_key
            )

            chain = load_qa_chain(llm, chain_type="stuff")
            answer = chain.run(input_documents=docs, question=user_question)

            st.subheader("ğŸ’¡ Cevap")
            st.success(answer)  # yeÅŸil kutuda gÃ¶ster

if __name__ == "__main__":
    main()
